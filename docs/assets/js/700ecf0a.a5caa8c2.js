"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[655],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var o=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,a=function(e,t){if(null==e)return{};var n,o,a={},s=Object.keys(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(o=0;o<s.length;o++)n=s[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=o.createContext({}),p=function(e){var t=o.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=p(e.components);return o.createElement(i.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},m=o.forwardRef((function(e,t){var n=e.components,a=e.mdxType,s=e.originalType,i=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=p(n),h=a,d=m["".concat(i,".").concat(h)]||m[h]||c[h]||s;return n?o.createElement(d,r(r({ref:t},u),{},{components:n})):o.createElement(d,r({ref:t},u))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var s=n.length,r=new Array(s);r[0]=m;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:a,r[1]=l;for(var p=2;p<s;p++)r[p]=n[p];return o.createElement.apply(null,r)}return o.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3158:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var o=n(7462),a=(n(7294),n(3905));const s={},r="Optional components",l={unversionedId:"optional-components",id:"optional-components",title:"Optional components",description:"The Piraeus Operator integrates with a number of optional external components. Not every cluster is configured to",source:"@site/docs/06.optional-components.md",sourceDirName:".",slug:"/optional-components",permalink:"/docs/optional-components",draft:!1,editUrl:"https://github.com/piraeusdatastore/docs/06.optional-components.md",tags:[],version:"current",sidebarPosition:6,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Security",permalink:"/docs/security"},next:{title:"Influencing Kubernetes scheduling",permalink:"/docs/scheduling"}},i={},p=[{value:"Snapshot support components",id:"snapshot-support-components",level:2},{value:"Using snapshots",id:"using-snapshots",level:3},{value:"CSI Volume Cloning",id:"csi-volume-cloning",level:3},{value:"Monitoring with Prometheus",id:"monitoring-with-prometheus",level:2},{value:"Linstor Controller Monitoring",id:"linstor-controller-monitoring",level:3},{value:"DRBD Resource Monitoring",id:"drbd-resource-monitoring",level:3},{value:"High Availability Controller",id:"high-availability-controller",level:2},{value:"Usage with STORK",id:"usage-with-stork",level:3},{value:"Scheduler components",id:"scheduler-components",level:2}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,o.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"optional-components"},"Optional components"),(0,a.kt)("p",null,"The Piraeus Operator integrates with a number of optional external components. Not every cluster is configured to\nprovide these external components by default. Piraeus provides integration with:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#snapshot-support-components"},"Volume Snapshots")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#monitoring-with-prometheus"},"Monitoring with Prometheus"))),(0,a.kt)("p",null,"The operator also installs some optional, piraeus-specific components by default:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#high-availability-controller"},"High Availabiltiy Controller")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#scheduler-components"},"Stork scheduler"))),(0,a.kt)("p",null,"These components are installed to show the full feature set of Piraeus. They can be disabled without affecting the other\ncomponents."),(0,a.kt)("h2",{id:"snapshot-support-components"},"Snapshot support components"),(0,a.kt)("p",null,"Snapshots in Kubernetes require 3 different components to work together. Not all Kubernetes distributions package these\ncomponents by default. Follow the steps below to find out how you can enable snapshots on your cluster."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The cluster needs to have the snapshot CRDs installed. To check whether your cluster has them installed or not, run:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"$ kubectl get crds volumesnapshots.snapshot.storage.k8s.io volumesnapshotclasses.snapshot.storage.k8s.io volumesnapshotcontents.snapshot.storage.k8s.io\nNAME                                             CREATED AT\nvolumesnapshots.snapshot.storage.k8s.io          2021-07-13T07:53:02Z\nvolumesnapshotclasses.snapshot.storage.k8s.io    2021-07-13T07:53:01Z\nvolumesnapshotcontents.snapshot.storage.k8s.io   2021-07-13T07:53:04Z\n")),(0,a.kt)("p",{parentName:"li"},"If your cluster doesn't have them installed, you can install them from ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-csi/external-snapshotter/tree/master/client/config/crd"},"here"),":"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"kubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v4.1.1/client/config/crd/snapshot.storage.k8s.io_volumesnapshotclasses.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v4.1.1/client/config/crd/snapshot.storage.k8s.io_volumesnapshots.yaml\nkubectl apply -f https://raw.githubusercontent.com/kubernetes-csi/external-snapshotter/v4.1.1/client/config/crd/snapshot.storage.k8s.io_volumesnapshotcontents.yaml\n")),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"NOTE")),": you should replace ",(0,a.kt)("inlineCode",{parentName:"p"},"v4.1.1")," in the above commands with the latest ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-csi/external-snapshotter/releases"},"release"),"\nrecommended for your Kubernetes version.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Snapshot requests in Kubernetes are first processed by a cluster-wide snapshot controller. If you had to manually add the CRDs to the cluster in the step above,\nchances are you also need to deploy the snapshot controller."),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"NOTE")),": If in step 1 the CRDs where already pre-installed in your cluster, you almost certainly can skip this step. Your Kubernetes distribution\nshould already include the snapshot controller."),(0,a.kt)("p",{parentName:"li"},"The Piraeus team provides 2 Helm charts to quickly deploy some ",(0,a.kt)("a",{parentName:"p",href:"https://artifacthub.io/packages/helm/piraeus-charts/snapshot-validation-webhook"},"additional validation"),"\nfor snapshot resource and the ",(0,a.kt)("a",{parentName:"p",href:"https://artifacthub.io/packages/helm/piraeus-charts/snapshot-controller"},"snapshot controller")," it self."),(0,a.kt)("p",{parentName:"li"},"Deployment should work out of the box on most clusters. Additional configuration options are available, please\ntake a look at the chart documentation linked above."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre"},"$ kubectl create namespace snapshot-controller\n$ helm repo add piraeus-charts https://piraeus.io/helm-charts/\n$ helm install validation-webhook piraeus-charts/snapshot-validation-webhook --namespace snapshot-controller\n$ helm install snapshot-controller piraeus-charts/snapshot-controller --namespace snapshot-controller\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The last component is a driver-specific snapshot implementation. This is included in any Piraeus installation and\nrequires no further steps. Every CSI Controller deployment of Piraeus also deploys the snapshotter sidecar, that\nultimately triggers snapshot creation in LINSTOR."),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},(0,a.kt)("em",{parentName:"strong"},"NOTE")),": If the CRDs are not deployed, the snapshotter sidecar will continuously warn about the missing CRDs.\nThis can be ignored."))),(0,a.kt)("h3",{id:"using-snapshots"},"Using snapshots"),(0,a.kt)("p",null,"To use snapshots, you first need to create a ",(0,a.kt)("inlineCode",{parentName:"p"},"VolumeSnapshotClass"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: snapshot.storage.k8s.io/v1beta1\nkind: VolumeSnapshotClass\nmetadata:\n  name: my-first-linstor-snapshot-class\ndriver: linstor.csi.linbit.com\ndeletionPolicy: Delete\n")),(0,a.kt)("p",null,"You can then use this snapshot class to create a snapshot from an existing LINSTOR PVC:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: snapshot.storage.k8s.io/v1beta1\nkind: VolumeSnapshot\nmetadata:\n  name: my-first-linstor-snapshot\nspec:\n  volumeSnapshotClassName: my-first-linstor-snapshot-class\n  source:\n    persistentVolumeClaimName: my-first-linstor-volume\n")),(0,a.kt)("p",null,"After a short wait, the snapshot will be ready:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"$ kubectl describe volumesnapshots.snapshot.storage.k8s.io my-first-linstor-snapshot\n...\nSpec:\n  Source:\n    Persistent Volume Claim Name:  my-first-linstor-snapshot\n  Volume Snapshot Class Name:      my-first-linstor-snapshot-class\nStatus:\n  Bound Volume Snapshot Content Name:  snapcontent-b6072ab7-6ddf-482b-a4e3-693088136d2c\n  Creation Time:                       2020-06-04T13:02:28Z\n  Ready To Use:                        true\n  Restore Size:                        500Mi\n")),(0,a.kt)("p",null,"You can restore the content of this snaphost by creating a new PVC with the snapshot as source:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-first-linstor-volume-from-snapshot\nspec:\n  storageClassName: linstor-basic-storage-class\n  dataSource:\n    name: my-first-linstor-snapshot\n    kind: VolumeSnapshot\n    apiGroup: snapshot.storage.k8s.io\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Mi\n")),(0,a.kt)("h3",{id:"csi-volume-cloning"},"CSI Volume Cloning"),(0,a.kt)("p",null,"Based on the concept of snapshots LINSTOR also supports cloning of persistent volumes - or to be more precise: of existing\npersistent volume claims (PVC). The CSI specification mentions some restrictions regarding namespace and storage classes\nof a PVC clone (see ",(0,a.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource/"},"Kubernetes documentation")," for details).\nIn regard to LINSTOR a clone requires that the volume was created using a LINSTOR storage pool which supports snapshots\n(i.e. a LVMTHIN pool). The new volume will be placed on the same nodes as the original (this can later change during\nuse, but you can't directly clone to a completely different node)."),(0,a.kt)("p",null,"To clone a volume create a new PVC and define the origin PVC in the dataSource:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: my-cloned-pvc\nspec:\n  storageClassName: linstor-basic-storage-class\n  dataSource:\n    name: my-origin-linstor-pvc\n    kind: PersistentVolumeClaim\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 500Mi\n")),(0,a.kt)("h2",{id:"monitoring-with-prometheus"},"Monitoring with Prometheus"),(0,a.kt)("p",null,"Starting with operator version 1.5.0, you can use ",(0,a.kt)("a",{parentName:"p",href:"https://prometheus.io/"},"Prometheus")," to monitor Piraeus components.\nThe operator will set up monitoring containers along the existing components and make them available as a ",(0,a.kt)("inlineCode",{parentName:"p"},"Service"),"."),(0,a.kt)("p",null,"If you use the ",(0,a.kt)("a",{parentName:"p",href:"https://prometheus-operator.dev/"},"Prometheus Operator"),", the Piraeus Operator will also set up the ",(0,a.kt)("inlineCode",{parentName:"p"},"ServiceMonitor"),"\ninstances. The metrics will automatically be collected by the Prometheus instance associated to the operator, assuming\n",(0,a.kt)("a",{parentName:"p",href:"https://prometheus-operator.dev/docs/kube/monitoring-other-namespaces/"},"watching the Piraeus namespace is enabled"),"."),(0,a.kt)("h3",{id:"linstor-controller-monitoring"},"Linstor Controller Monitoring"),(0,a.kt)("p",null,"The Linstor Controller exports cluster-wide metrics. Metrics are exported on the existing controller service, using the\npath ",(0,a.kt)("a",{parentName:"p",href:"https://linbit.com/drbd-user-guide/linstor-guide-1_0-en/#s-linstor-monitoring"},(0,a.kt)("inlineCode",{parentName:"a"},"/metrics")),"."),(0,a.kt)("h3",{id:"drbd-resource-monitoring"},"DRBD Resource Monitoring"),(0,a.kt)("p",null,"All satellites are bundled with a secondary container that uses ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/LINBIT/drbd-reactor/"},(0,a.kt)("inlineCode",{parentName:"a"},"drbd-reactor")),"\nto export metrics directly from DRBD. The metrics are available on port 9942, for convenience a headless service named\n",(0,a.kt)("inlineCode",{parentName:"p"},"<linstorsatelliteset-name>-monitoring")," is provided."),(0,a.kt)("p",null,"If you want to disable the monitoring container, set ",(0,a.kt)("inlineCode",{parentName:"p"},"monitoringImage")," to ",(0,a.kt)("inlineCode",{parentName:"p"},'""')," in your LinstorSatelliteSet resource."),(0,a.kt)("h2",{id:"high-availability-controller"},"High Availability Controller"),(0,a.kt)("p",null,"The ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/piraeusdatastore/piraeus-ha-controller"},"Piraeus High Availability (HA) Controller")," will speed up the fail over process for stateful workloads using Piraeus for\nstorage. Using the HA Controller reduces the time it takes for Kubernetes to reschedule a Pod using faulty storage from\n15min to 45seconds (exact times depend on your Kubernetes set up)."),(0,a.kt)("p",null,"To mark your stateful applications as managed by Piraeus, use the ",(0,a.kt)("inlineCode",{parentName:"p"},"linstor.csi.linbit.com/on-storage-lost: remove")," label.\nFor example, Pod Templates in a StatefulSet should look like:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: my-stateful-app\nspec:\n  serviceName: my-stateful-app\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: my-stateful-app\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: my-stateful-app\n        linstor.csi.linbit.com/on-storage-lost: remove\n    ...\n")),(0,a.kt)("p",null,"This way, the Piraeus High Availability Controller will not interfere with applications that do not benefit or even\nsupport it's primary use."),(0,a.kt)("p",null,"To disable deployment of the HA Controller use:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"--set haController.enabled=false\n")),(0,a.kt)("h3",{id:"usage-with-stork"},"Usage with STORK"),(0,a.kt)("p",null,"STORK is a scheduler extender plugin and storage health monitoring tool (see below). There is considerable overlap\nbetween the functionality of STORK and the HA Controller."),(0,a.kt)("p",null,"Like the HA Controller, STORK will also delete Pods which use faulty volumes. In contrast to the HA Controller, STORK\ndoes not discriminate based on labels on the Pod."),(0,a.kt)("p",null,"Another difference between the two is that the HA Controller reacts faster on storage failures, as it watches the\nraw event stream from Piraeus, while STORK just periodically checks the volume status."),(0,a.kt)("p",null,"While they overlap in functionality, there are no known compatibility issues when running both STORK and the HA Controller."),(0,a.kt)("h2",{id:"scheduler-components"},"Scheduler components"),(0,a.kt)("p",null,"Stork is a scheduler extender plugin for Kubernetes which allows a storage driver to give the Kubernetes scheduler\nhints about where to place a new pod so that it is optimally located for storage performance. You can learn more\nabout the project on its ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/libopenstorage/stork"},"GitHub page"),"."),(0,a.kt)("p",null,"By default, the operator will install the components required for Stork, and register a new scheduler called ",(0,a.kt)("inlineCode",{parentName:"p"},"stork"),"\nwith Kubernetes. This new scheduler can be used to place pods near to their volumes."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\n  namespace: default\nspec:\n  schedulerName: stork\n  containers:\n  - name: busybox\n    image: busybox\n    command: ["tail", "-f", "/dev/null"]\n    volumeMounts:\n    - name: my-first-linstor-volume\n      mountPath: /data\n    ports:\n    - containerPort: 80\n  volumes:\n  - name: my-first-linstor-volume\n    persistentVolumeClaim:\n      claimName: "test-volume"\n')),(0,a.kt)("p",null,"Deployment of the scheduler can be disabled using"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"--set stork.enabled=false\n")))}c.isMDXComponent=!0}}]);